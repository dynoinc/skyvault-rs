# Helm Chart Configuration for local development

# Common configuration for all Skyvault instances
common:
  image:
    id: localhost/skyvault:dev
    pullPolicy: IfNotPresent

  # Extra labels to add to all pods
  extraLabels: {}
    # example-label: "example-value"
    # team: "platform"

  # Sensitive configuration values
  secrets:
    # AWS credentials
    AWS_ACCESS_KEY_ID: minioadmin
    AWS_SECRET_ACCESS_KEY: minioadmin
    
    # Postgres credentials
    SKYVAULT_POSTGRES_PASSWORD: postgres

  env:
    # S3
    AWS_REGION: us-east-1
    AWS_ENDPOINT_URL_S3: http://skyvault-minio:9000
    SKYVAULT_S3_BUCKET: skyvault-bucket

    # Postgres
    SKYVAULT_POSTGRES_USER: postgres
    SKYVAULT_POSTGRES_DB: skyvault
    SKYVAULT_POSTGRES_HOST: skyvault-postgres
    SKYVAULT_POSTGRES_PORT: 5432
    SKYVAULT_POSTGRES_SSLMODE: allow

    # OpenTelemetry
    # For HTTP: use port 4318 with protocol "http" (includes /v1/metrics path)
    # For gRPC: use port 4317 with protocol "grpc" (no path needed)
    OTEL_EXPORTER_OTLP_ENDPOINT: http://skyvault-otel-collector:4317
    OTEL_EXPORTER_OTLP_PROTOCOL: grpc

    # Rust
    RUST_BACKTRACE: 1
    RUST_LOG: "skyvault=debug"

    # Sentry
    SENTRY_SAMPLE_RATE: 1.0

deployments:
  reader:
    enabled: false
    instanceName: "reader"
    replicaCount: 1
    resources:
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 200m
        memory: 256Mi
    service:
      type: NodePort
      port: 50051
      nodePort: 30051
    env:
      SKYVAULT_SERVICE: "reader"
      SKYVAULT_READER_CACHE_LABEL_SELECTOR: "app.kubernetes.io/component=skyvault-cache"
      SKYVAULT_READER_CACHE_PORT: 50051

  cache:
    enabled: false
    instanceName: "cache"
    replicaCount: 1
    resources:
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 200m
        memory: 256Mi
    service:
      type: ClusterIP
      port: 50051
    cache:
      # Volume type: "tmpfs", "pvc", or "none"
      volumeType: none
      tmpfs:
        # Size limit for tmpfs (e.g., "1Gi", "512Mi")
        sizeLimit: 1Gi
      # Configuration for PVC volume
      pvc:
        # Storage class for PVC (leave empty for default)
        storageClass: standard
        # Size of PVC (e.g., "10Gi", "5Gi")
        size: 10Gi
        # Access mode for PVC
        accessMode: ReadWriteOnce
    # Instance-specific environment variables
    env:
      SKYVAULT_SERVICE: "cache"
    # Extra labels specific to cache pods
    extraLabels: {}
      # cache-specific-label: "cache-value"

  writer:
    enabled: false
    instanceName: "writer"
    replicaCount: 1
    resources:
      limits:
        cpu: 1000m
        memory: 1Gi
      requests:
        cpu: 500m
        memory: 512Mi
    service:
      type: NodePort
      port: 50051
      nodePort: 30052
    env:
      SKYVAULT_SERVICE: "writer"
    # Dynamic configuration specific to writer
    dynamicConfig:
      writerConcurrentUploads: "2"

  orchestrator:
    enabled: false
    instanceName: "orchestrator"
    replicaCount: 1
    resources:
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 200m
        memory: 256Mi
    service:
      type: NodePort
      port: 50051
      nodePort: 30053
    env:
      SKYVAULT_SERVICE: "orchestrator"
      SENTRY_SAMPLE_RATE: 0.01
    # Dynamic configuration specific to orchestrator
    dynamicConfig:
      orchestratorJobRetryLimit: "3"

# WAL Compactor - continuously compacts WAL runs
walCompactor:
  enabled: true
  instanceName: "wal-compactor"
  replicaCount: 1
  resources:
    limits:
      cpu: 500m
      memory: 1Gi
    requests:
      cpu: 100m
      memory: 512Mi
  env: {}
  extraLabels: {}

# Service account configuration
serviceAccount:
  create: true
  annotations: {}

# Dynamic configurations for job types
jobDynamicConfigs:
  # WAL compaction job configuration
  wal-compaction:
    writerConcurrentUploads: "4"
    orchestratorJobRetryLimit: "3"
  
  # Table buffer compaction job configuration  
  table-buffer-compaction:
    writerConcurrentUploads: "6"
    orchestratorJobRetryLimit: "5"
  
  # Table tree compaction job configuration
  table-tree-compaction:
    writerConcurrentUploads: "8"
    orchestratorJobRetryLimit: "5"

# Values for the minio service
minio:
  enabled: true
  image:
    repository: docker.io/minio/minio
    tag: latest
    pullPolicy: IfNotPresent
  service:
    port: 9000
    type: ClusterIP

# Values for the PostgreSQL service
postgres:
  enabled: true
  image:
    repository: docker.io/postgres
    tag: "12"
    pullPolicy: IfNotPresent
  service:
    port: 5432
    type: ClusterIP

# Values for the OpenTelemetry Collector
otelCollector:
  enabled: true
  replicaCount: 1
  
  image:
    repository: otel/opentelemetry-collector
    tag: "0.128.0"
    pullPolicy: IfNotPresent
  
  service:
    type: ClusterIP
  
  resources:
    limits:
      cpu: 200m
      memory: 256Mi
    requests:
      cpu: 100m
      memory: 128Mi
